# Preprocessing input data for activity recognition engine

## Steps done

### Collect Unity dataset for each activity (250 RGB frames + labels captures.json)

The run button cannot be called multiple times from Unity platform; so I used linux xdotool to repeat mouse movement and click 1k times the run button for each camera view (4). Obviously this is done for all the 3 activities, so we have 1000 x 4 x 3 samples = 12k.

### Convert Unity dataset to oid format

For each Activity now I wrote and run unity2oid.py script to:

- Rename & sort the Unity (raw) dataset;
- Convert it to oid folder (RGB + labels for bounding boxes) all into train_folder;
- Given config.ini specification compute the train/val split (80% - 20%).

![image](https://user-images.githubusercontent.com/43888007/115261908-54528e80-a134-11eb-82aa-e4f670e9cdf4.png)


### Convert oid dataset to our final preprocessed ar_dataset
