# AR engine



The engine was carried out step by step, putting together different works and results obtained, with the aim of creating a cascade structure, characterized by:


_________________________________________

### TRAINING

INPUT (Unity synthetic dataset) (Activities: HANDS UP, WAVING HANDS, MAN DOWN)

Unity labeling tools to detect people bounding boxes: a python script will [crop for it the next step](./mandown.gif)

[Skeleton Estimation](./SkeletonEstimation/ReadMe.md) <--> Tensorflow serving (models.pb)

Custom LSTM/CNN training papeline (with Continuous Learning approach)

OUTPUT (model.pb)

__________________________________________

### INFERENCE


INPUT (Unity or real scenes) (Activities: HANDS UP, WAVING HANDS, MAN DOWN)

[Person detection engine (YOLOv4)](./PersonDetection/ReadMe.md) <--> Tensorflow serving (models.pb)

[Skeleton Estimation](./SkeletonEstimation/ReadMe.md) <--> Tensorflow serving (models.pb)

LSTM (with trained model) or CNN inference <--> Tensorflow serving (models.pb)

OUTPUT (for each scene recognize the activity)

